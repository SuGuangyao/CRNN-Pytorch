{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.nn import CTCLoss\n",
    "\n",
    "from dataset import Synth90kDataset, synth90k_collate_fn\n",
    "from model import CRNN\n",
    "from evaluate import evaluate\n",
    "from config import train_config as config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练辅助函数\n",
    "\n",
    "### 注意\n",
    "\n",
    "1. 尺度\n",
    "\n",
    "- images: (N, C, H, W) -> (32, 1, 32, 100)\n",
    "- targets：(X, ),一维向量，长度不固定。32个batch标签（向量）拼接成一个长向量，target_lengths指定切割位置\n",
    "- logits：(T, N, n_class) -> (24, 32, 37)\n",
    "- input_lengths: (N,) -> (32, ), 向量中每一个值表识相应batch输入序列长度,为T即24,表示输入序列长度固定为24\n",
    "- target_lengths: (N, ) ->(32, ), 向量中每一个值表示相应batch训练图像label长度，长度不固定\n",
    "\n",
    "2. CTCLoss函数使用说明。\n",
    "\n",
    "1) 获取CTCLoss()对象\n",
    "\n",
    "```\n",
    "ctc_loss = nn.CTCLoss(blank=len(CHARS)-1, reduction='mean')\n",
    "```\n",
    "\n",
    "- blank：空白标签所在的label值，默认为0，需要根据实际的标签定义进行设定；\n",
    "\n",
    "- reduction：处理output losses的方式，string类型，可选'none' 、 'mean' 及 'sum'，'none'表示对output losses不做任何处理，'mean' 则对output losses取平均值处理，'sum'则是对output losses求和处理，默认为'mean' 。\n",
    "\n",
    "2) 在迭代中调用CTCLoss()对象计算损失值\n",
    "```\n",
    "loss = ctc_loss(log_probs, targets, input_lengths, target_lengths)\n",
    "```\n",
    "\n",
    "- log_probs：shape为(T, N, C)的模型输出张量，其中，T表示CTCLoss的输入长度也即输出序列长度，N表示训练的batch size长度，C则表示包含有空白标签的所有要预测的字符集总长度，log_probs一般需要经过torch.nn.functional.log_softmax处理后再送入到CTCLoss中；\n",
    "\n",
    "- targets：shape为(N, S) 或(sum(target_lengths))的张量，其中第一种类型，N表示训练的batch size长度，S则为标签长度，第二种类型，则为所有标签长度之和，但是需要注意的是targets不能包含有空白标签；\n",
    "\n",
    "- input_lengths：shape为(N)的张量或元组，但每一个元素的长度必须等于T即输出序列长度，一般来说模型输出序列固定后则该张量或元组的元素值均相同；\n",
    "\n",
    "- target_lengths：shape为(N)的张量或元组，其每一个元素指示每个训练输入序列的标签长度，但标签长度是可以变化的；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(crnn, data, optimizer, criterion, device):\n",
    "    crnn.train()\n",
    "    images, targets, target_lengths = [d.to(device) for d in data]\n",
    "\n",
    "    logits = crnn(images)\n",
    "    log_probs = torch.nn.functional.log_softmax(logits, dim=2)\n",
    "\n",
    "    batch_size = images.size(0)\n",
    "    input_lengths = torch.LongTensor([logits.size(0)] * batch_size)\n",
    "    target_lengths = torch.flatten(target_lengths)\n",
    "\n",
    "    loss = criterion(log_probs, targets, input_lengths, target_lengths)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 超参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = config['epochs']\n",
    "train_batch_size = config['train_batch_size']\n",
    "eval_batch_size = config['eval_batch_size']\n",
    "lr = config['lr']\n",
    "show_interval = config['show_interval']\n",
    "valid_interval = config['valid_interval']\n",
    "save_interval = config['save_interval']\n",
    "cpu_workers = config['cpu_workers']\n",
    "reload_checkpoint = config['reload_checkpoint']\n",
    "valid_max_iter = config['valid_max_iter']\n",
    "\n",
    "img_width = config['img_width']\n",
    "img_height = config['img_height']\n",
    "data_dir = config['data_dir']\n",
    "\n",
    "num_class = len(Synth90kDataset.LABEL2CHAR) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 判断cuda是否可用，是则基于GPU训练，否则用cpu训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 设置训练数据加载器、验证数据加载器，常规操作\n",
    "\n",
    "#### collate_fn用法\n",
    "- 把list类型batch（若不加此操作，原先一个batch中的多个sample是在list中的）转换成Tensor，加速运算。\n",
    "- 经collate_fn处理，返回符合需求的数据及相应尺度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Synth90kDataset(root_dir=data_dir, mode='train',\n",
    "                                    img_height=img_height, img_width=img_width)\n",
    "valid_dataset = Synth90kDataset(root_dir=data_dir, mode='dev',\n",
    "                                img_height=img_height, img_width=img_width)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=train_batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=cpu_workers,\n",
    "    collate_fn=synth90k_collate_fn)\n",
    "valid_loader = DataLoader(\n",
    "    dataset=valid_dataset,\n",
    "    batch_size=eval_batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=cpu_workers,\n",
    "    collate_fn=synth90k_collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实例化CRNN模型，加载模型参数，并运行至可用设备（CPU or GPU）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRNN(\n",
       "  (cnn): Sequential(\n",
       "    (conv0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (relu0): ReLU(inplace=True)\n",
       "    (pooling0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (relu1): ReLU(inplace=True)\n",
       "    (pooling1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (relu2): ReLU(inplace=True)\n",
       "    (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (relu3): ReLU(inplace=True)\n",
       "    (pooling2): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv4): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (batchnorm4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu4): ReLU(inplace=True)\n",
       "    (conv5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (batchnorm5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu5): ReLU(inplace=True)\n",
       "    (pooling3): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    (conv6): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1))\n",
       "    (relu6): ReLU(inplace=True)\n",
       "  )\n",
       "  (map_to_seq): Linear(in_features=512, out_features=64, bias=True)\n",
       "  (rnn1): LSTM(64, 256, bidirectional=True)\n",
       "  (rnn2): LSTM(512, 256, bidirectional=True)\n",
       "  (dense): Linear(in_features=512, out_features=37, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crnn = CRNN(1, img_height, img_width, num_class,\n",
    "            map_to_seq_hidden=config['map_to_seq_hidden'],\n",
    "            rnn_hidden=config['rnn_hidden'],\n",
    "            leaky_relu=config['leaky_relu'])\n",
    "if reload_checkpoint:\n",
    "    crnn.load_state_dict(torch.load(reload_checkpoint, map_location=device))\n",
    "crnn.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义优化方法、损失函数\n",
    "CTC 的全称是Connectionist Temporal Classification，中文名称是“连接时序分类”，这个方法主要是解决神经网络label 和output 不对齐的问题（Alignment problem），其优点是不用强制对齐标签且标签可变长，仅需输入序列和监督标签序列即可进行训练，目前，该方法主要应用于场景文本识别（scene text recognition）、语音识别（speech recognition）及手写字识别（handwriting recognition）等工程场景。以往我们在百度上搜索pytorch + ctc loss得到的结果基本上warp-ctc的使用方法，warp-ctc是百度开源的一个可以应用在CPU和GPU上高效并行的CTC代码库，但是为了在pytorch上使用warp-ctc我们不仅需要编译其源代码还需要进行安装配置，使用起来着实麻烦。而在Pytorch 1.0.x版本内早就有内置ctc loss接口了，我们完全可以直接使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CTCLoss()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = optim.RMSprop(crnn.parameters(), lr=lr)\n",
    "criterion = CTCLoss(reduction='sum')\n",
    "criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert save_interval % valid_interval == 0\n",
    "i = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "train_batch_loss[ 10 ]:  26.11614227294922\n",
      "train_batch_loss[ 20 ]:  25.46373748779297\n",
      "train_batch_loss[ 30 ]:  26.30978012084961\n",
      "train_batch_loss[ 40 ]:  25.977890014648438\n",
      "train_batch_loss[ 50 ]:  25.009597778320312\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-d66e1e15da15>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mtot_train_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mtrain_data\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcrnn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mtrain_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-cd97b7aa5372>\u001b[0m in \u001b[0;36mtrain_batch\u001b[1;34m(crnn, data, optimizer, criterion, device)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\env\\python\\crnn\\lib\\site-packages\\torch\\optim\\rmsprop.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m     98\u001b[0m                     \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lr'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m                     \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lr'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mavg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    print(f'epoch: {epoch}')\n",
    "    tot_train_loss = 0.\n",
    "    tot_train_count = 0\n",
    "    for train_data in train_loader:\n",
    "        loss = train_batch(crnn, train_data, optimizer, criterion, device)\n",
    "        train_size = train_data[0].size(0)\n",
    "\n",
    "        tot_train_loss += loss\n",
    "        tot_train_count += train_size\n",
    "        if i % show_interval == 0:\n",
    "            print('train_batch_loss[', i, ']: ', loss / train_size)\n",
    "\n",
    "        if i % valid_interval == 0:\n",
    "            evaluation = evaluate(crnn, valid_loader, criterion,\n",
    "                                  decode_method=config['decode_method'],\n",
    "                                  beam_size=config['beam_size'])\n",
    "            print('valid_evaluation: loss={loss}, acc={acc}'.format(**evaluation))\n",
    "\n",
    "        if i % save_interval == 0:\n",
    "            prefix = 'crnn'\n",
    "            loss = evaluation['loss']\n",
    "            save_model_path = os.path.join(config['checkpoints_dir'],\n",
    "                                           f'{prefix}_{i:06}_loss{loss}.pt')\n",
    "            torch.save(crnn.state_dict(), save_model_path)\n",
    "            print('save model at ', save_model_path)\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    print('train_loss: ', tot_train_loss / tot_train_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}